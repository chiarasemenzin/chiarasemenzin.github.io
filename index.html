<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="google-site-verification" content="atvvEYHtIZApIXfmY2wfl81J4EpIRBls13iQF1crs6A" />
    <meta name="description" content="Chiara Semenzin - Linguist and Cognitive Scientist researching dolphin communication using AI and computational methods at ENS Paris">
    <meta name="keywords" content="Chiara Semenzin, linguistics, cognitive science, dolphin communication, AI, computational linguistics">
    <title>Chiara Semenzin</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
<div class="container">

<h1>Chiara Semenzin</h1>

<div class="profile">
    <img src="photo.png" alt="Your Photo">
    <div class="bio">
        <p>My research explores how artificial intelligence can help us decipher the structure and meaning of non-human communication systems.</p>
        <p>After earning degrees in <strong>Linguistics (MA)</strong> and <strong>Informatics & Cognitive Science (MSc)</strong> from the University of Edinburgh, I now work at the crossroads of language, computation, and biology ‚Äî studying how intelligence emerges across species and representations.</p>
        <p>Currently, I am a <strong>postdoctoral researcher at ENS Paris</strong>, where I develop machine learning and information-theoretic methods to uncover patterns in dolphin vocalizations and probe the limits of speech models beyond the human domain.</p>
        <p>I also collaborate with <strong>No√®se</strong>, a venture that is <em>revolutionizing academic and career guidance</em> by merging cognitive science and AI to align individual aspirations with professional opportunities.</p>
        <p>Beyond research, I am passionate about science communication and interdisciplinary dialogue ‚Äî building bridges between linguistics, artificial intelligence, and the natural world.</p>
    </div>

</div>

<div class="section news">
    <h2>News</h2>
    <div class="news-box">
        <ul>
            <li>üé§ 28/2/2025 I presented my latest work at the Embedded Days Conference in Paris</li>
            <li>üî¨ 14/10/2024 Shared my work on dolphins with the general public at the F√™te de la Science in Paris!</li>
            <li>üéì 25/10/2024 Held a guest lecture at University of Siena about Generative AI and why it can make our life better</li>
            <li>üê¨ Presented my work on dolphin communication at the Non-Human Communication Workshop III by CETI in Berkeley</li>
        </ul>
    </div>
</div>

<div class="section publications">
    <h2>Selected Publications</h2>

    <div class="publication-item">
        <div class="pub-figure">
            <img src="dolph2vec-figure.png" alt="Dolph2Vec Embeddings" class="pub-img">
            <p class="figure-caption">Dolph2Vec embeddings capture biologically meaningful categories</p>
        </div>
        <div class="pub-content">
            <p class="pub-citation">
                <strong>Semenzin, C.</strong>, Mustun, F., Dess√¨, R., Emanuelli, A., Orhan, P., Lakretz, Y., de Polavieja, G., Sumbre, G. (2025).
                Dolph2Vec: Self-Supervised Representations of Dolphin Vocalizations.
                <span class="pub-tag">Preprint</span>
            </p>
            <p class="pub-summary">Dolph2Vec, self-supervised, species-specific model significantly outperforms general-purpose baselines in detection and classification. The learned embeddings capture interpretable dolphin whistle categories, enabling fine-grained analysis of communication patterns.</p>
        </div>
    </div>

    <div class="publication-item">
        <div class="pub-figure">
            <img src="whistle-variability.png" alt="Whistle Variability Results" class="pub-img">
            <p class="figure-caption">Visualization of social acoustic interactions in a pod of dolphins</p>
        </div>
        <div class="pub-content">
            <p class="pub-citation">
                Mustun, F.*, <strong>Semenzin, C.*</strong>, Rance, D., Marachlian, E., Guillerm, Z., Mancini, A., Bouaziz, I., Fleck, E., Shashar, N., de Polavieja, G., Sumbre, G. (2024).
                Whistle variability and social acoustic interactions in bottlenose dolphins.
                <span class="pub-tag">In Review</span>
            </p>
            <p class="pub-summary">Signature whistles vary systematically, forming distinct sub-categories that mirror social structures and serve different communicative roles. Remarkably, dolphins were also observed producing the signature whistles of their deceased mothers‚Äîa behavior previously seen only in humans.</p>
        </div>
    </div>

    <div class="publication-item">
        <div class="pub-figure">
            <img src="correlations.png" alt="Zooniverse Annotation Results" class="pub-img">
            <p class="figure-caption">Citizen science annotation VS Gold standard</p>
        </div>
        <div class="pub-content">
            <p class="pub-citation">
                <strong>Semenzin, C.</strong>, Hamrick, L., Seidl, A., Kelleher, B., Cristia, A. (2021).
                Towards large-scale data annotation of audio from wearables: validating zooniverse annotations of infant vocalization types.
                <em>IEEE Spoken Language Technology Workshop (SLT)</em>, pp. 1079‚Äì1085.
            </p>
            <p class="pub-summary">Classification of individual vocalizations on Zooniverse was overall moderately accurate compared to the laboratory gold standard.</p>
        </div>
    </div>

    <div class="publication-item">
        <div class="pub-figure">
            <img src="zooniverse.png" alt="Big Data Vocalization Analysis" class="pub-img">
            <p class="figure-caption">Vocalization patterns in children</p>
        </div>
        <div class="pub-content">
            <p class="pub-citation">
                <strong>Semenzin, C.</strong>, Hamrick, L., Seidl, A., Kelleher, B.L., Cristia, A. (2021).
                Describing vocalizations in young children: A big data approach through citizen science annotation.
                <em>Journal of Speech, Language, and Hearing Research</em>.
            </p>
            <p class="pub-summary">A large dataset of infant speech was uploaded on a citizen science platform. The same data were annotated in the laboratory by highly trained annotators. An analysis of descriptors defined at the level of individuals found strong correlations between descriptors derived from Zooniverse versus laboratory annotations.</p>
        </div>
    </div>
</div>

<div class="section awards">
    <h2>Academic Awards & Honors</h2>
    <ul>
        <li>
            <strong>Marie Sklodowska-Curie Fellowship</strong> ‚Äî AI4Science (2021)<br>
            <span class="award-description">Prestigious EU fellowship for doctoral research in AI applications to biological sciences</span>
        </li>
        <li>
            <strong>Edinburgh University Rea Marmarinou Award</strong> ‚Äî Cognitive Science (July 2018)<br>
            <span class="award-description">Awarded for excellence in Cognitive Science research</span>
        </li>
        <li>
            <strong>School of Informatics Travel Award</strong> ‚Äî University of Edinburgh (May 2019)<br>
            <span class="award-description">Support for international conference participation</span>
        </li>
    </ul>
</div>

<div class="section talks">
    <h2>Invited Talks</h2>
    <ul>
        <li>
            <strong>Embed Days Colloquium</strong>, Paris (2025)<br>
            <em>"Unsupervised modeling of dolphin vocal structure"</em>
        </li>
        <li>
            <strong>EviL Meeting, Computational Linguistics Lab (COLT)</strong>, Universitat Pompeu Fabra, Barcelona, Spain (2025)<br>
            <em>"Social acoustic interactions in bottlenose dolphins"</em>
        </li>
        <li>
            <strong>REST-CL Workshop on Computational Linguistics</strong>, Tarragona, Spain (2024)<br>
            <em>"Social acoustic interactions in bottlenose dolphins"</em>
        </li>
        <li>
            <strong>AI Systems for Research Seminar Series</strong>, University of Siena, Italy (2024)<br>
            <em>"Generative AI Tools for Academic Literature Review and Research"</em>
        </li>
        <li>
            <strong>CETI Workshop: Non-Human Communication III</strong> (2024)<br>
            <em>"Whistle variability and social acoustic interactions in bottlenose dolphins"</em>
        </li>
        <li>
            <strong>LINGUAE Seminar Series</strong>, √âcole Normale Sup√©rieure (2024)<br>
            <em>"Statistical patterns in dolphin whistle variability"</em>
        </li>
        <li>
            <strong>Neurosection Department Seminar Series</strong>, Institut de Biologie de l'√âcole Normale Sup√©rieure, Paris (2023, 2024, 2025)<br>
            <em>"Whistle variability and social acoustic interactions in bottlenose dolphins"</em>
        </li>
        <li>
            <strong>AI4Science Conference</strong>, Nice (2022)<br>
            <em>"Statistical patterns in dolphin acoustic productions"</em>
        </li>
    </ul>

    <h3>Contributed Talks and Posters</h3>
    <ul class="contributed">
        <li><strong>PSL Doctoral Conference 2023</strong> ‚Äî Talk</li>
        <li><strong>PROTOLANG 2022</strong> ‚Äî Poster</li>
        <li><strong>Neuroethology 2022</strong> ‚Äî Poster</li>
    </ul>
</div>

<div class="section education">
    <h2>Education</h2>
    <ul>
        <li>
            <strong>2021 - Present</strong><br>
            √âcole Normale Sup√©rieure, Paris, France<br>
            Marie Sklodowska-Curie PhD Fellow
        </li>
        <li>
            <strong>2017 - 2019</strong><br>
            The University of Edinburgh, United Kingdom<br>
            MSc in Informatics and Cognitive Science
        </li>
        <li>
            <strong>2013 - 2017</strong><br>
            The University of Edinburgh, United Kingdom<br>
            Master of Arts with Honours in Linguistics
        </li>
    </ul>
</div>


<!-- Social Links -->
<div class="social">
    <h2>Connect with Me</h2>
    <div class="social-icons">
        <a href="https://github.com/chiarasemenzin/" target="_blank" rel="noopener noreferrer" aria-label="GitHub">
            <img src="https://cdn.jsdelivr.net/npm/simple-icons@v9/icons/github.svg" alt="GitHub" class="icon">
        </a>
        <a href="https://scholar.google.co.uk/citations?user=9astJoYAAAAJ&hl=fr&oi=ao" target="_blank" rel="noopener noreferrer" aria-label="Google Scholar">
            <img src="https://cdn.jsdelivr.net/npm/simple-icons@v9/icons/googlescholar.svg" alt="Google Scholar" class="icon">
        </a>
        <a href="https://www.linkedin.com/in/chiara-semenzin-85a93998/" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn">
            <img src="https://cdn.jsdelivr.net/npm/simple-icons@v9/icons/linkedin.svg" alt="LinkedIn" class="icon">
        </a>
        <a href="mailto:chiara.semenzin@gmail.com" aria-label="Email">
            <img src="https://cdn.jsdelivr.net/npm/simple-icons@v9/icons/gmail.svg" alt="Email" class="icon">
        </a>
    </div>
</div>

<footer>
    <p>&copy; 2025 Chiara Semenzin. All rights reserved.</p>
</footer>

</div>
</body>
</html>
